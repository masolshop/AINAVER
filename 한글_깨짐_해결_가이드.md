# í•œê¸€ ê¹¨ì§ ë¬¸ì œ í•´ê²° ê°€ì´ë“œ ğŸ”¥

## ğŸ“‹ ë¬¸ì œ ì¦ìƒ

**ì´ë¯¸ì§€ ì°¸ê³ **: ë„¤ì´ë²„ ê²€ìƒ‰ ê²°ê³¼ì—ì„œ í•œê¸€ì´ ë‹¤ìŒê³¼ ê°™ì´ ê¹¨ì ¸ì„œ í‘œì‹œë¨

```
âŒ ì´ì „ (ê¹¨ì§„ ë¬¸ì):
5â—†ë²¸ì’– â—†ëª„ëº–â—†ë¸³b ~ë²¸ì’–â—†ç“¸ï¿½ â—†ï¿½ëº–>
ì²«íš¨ë± â—†â—† å¨´ê³•â—†â—† æœã‰¿ì¨¬ â—†â—† å±±ê½µ ç¬‘ì‚¦â†’ì²«ï¿½ ë²¸ì’–â—†ç“¸ï¿½(ï¿½ë²ëº¤æª â—†â—†, 963~1021)
```

## ğŸ” ì›ì¸ ë¶„ì„

### 1. requests ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ìë™ ì¸ì½”ë”© ê°ì§€ ì‹¤íŒ¨
```python
response = requests.get(url, headers=headers)
# response.encodingì´ ìë™ìœ¼ë¡œ 'ISO-8859-1'ë¡œ ì„¤ì •ë¨ (ì˜ëª»ëœ ê°ì§€)
print(response.encoding)  # 'ISO-8859-1' ë˜ëŠ” 'None'
```

### 2. BeautifulSoupì˜ ì˜ëª»ëœ í…ìŠ¤íŠ¸ íŒŒì‹±
```python
soup = BeautifulSoup(response.text, 'lxml')
# response.textê°€ ì´ë¯¸ ì˜ëª»ëœ ì¸ì½”ë”©ìœ¼ë¡œ ë””ì½”ë”©ëœ ìƒíƒœ
# í•œê¸€ì´ ê¹¨ì§„ ë¬¸ìë¡œ ë³€í™˜ë¨
```

### 3. ë„¤ì´ë²„ ëª¨ë°”ì¼ í˜ì´ì§€ì˜ ì¸ì½”ë”© íŠ¹ì„±
- ë„¤ì´ë²„ ëª¨ë°”ì¼ í˜ì´ì§€ëŠ” UTF-8ë¡œ ì¸ì½”ë”©ë˜ì–´ ìˆìŒ
- í•˜ì§€ë§Œ HTTP í—¤ë”ì— charset ì •ë³´ê°€ ëª…í™•íˆ ëª…ì‹œë˜ì§€ ì•Šì„ ìˆ˜ ìˆìŒ
- requestsê°€ Content-Type í—¤ë”ë¥¼ ë³´ê³  ì˜ëª» ì¶”ì¸¡

## âœ… í•´ê²° ë°©ë²•

### ë°©ë²• 1: response.encoding ëª…ì‹œì  ì„¤ì • (ê¶Œì¥) â­
```python
import requests
from bs4 import BeautifulSoup

url = "https://m.search.naver.com/search.naver?query=í¬ì¥ì´ì‚¬"
response = requests.get(url, headers=headers)

# ğŸ”¥ í•µì‹¬: UTF-8 ì¸ì½”ë”© ëª…ì‹œì  ì„¤ì •
response.encoding = 'utf-8'

# ì´ì œ response.textê°€ ì˜¬ë°”ë¥´ê²Œ ë””ì½”ë”©ë¨
soup = BeautifulSoup(response.text, 'lxml')
```

**ì„¤ëª…**:
- `response.encoding`ì„ ëª…ì‹œì ìœ¼ë¡œ `'utf-8'`ë¡œ ì„¤ì •
- `response.text`ë¥¼ í˜¸ì¶œí•  ë•Œ UTF-8ë¡œ ë””ì½”ë”©ë¨
- í•œê¸€ì´ ì •ìƒì ìœ¼ë¡œ í‘œì‹œë¨

### ë°©ë²• 2: HTTP í—¤ë”ì— Accept-Charset ì¶”ê°€
```python
headers = {
    'User-Agent': 'Mozilla/5.0 ...',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
    'Accept-Language': 'ko-KR,ko;q=0.9',
    'Accept-Charset': 'utf-8',  # ğŸ”¥ UTF-8 ì¸ì½”ë”© ìš”ì²­
    'Connection': 'keep-alive',
}

response = requests.get(url, headers=headers)
response.encoding = 'utf-8'  # ì—¬ì „íˆ ëª…ì‹œì  ì„¤ì • í•„ìš”
```

### ë°©ë²• 3: response.content + ëª…ì‹œì  ë””ì½”ë“œ
```python
response = requests.get(url, headers=headers)

# response.contentëŠ” bytes íƒ€ì…
html = response.content.decode('utf-8', errors='ignore')

soup = BeautifulSoup(html, 'lxml')
```

**ì£¼ì˜**: `errors='ignore'`ëŠ” ê¹¨ì§„ ë¬¸ìë¥¼ ë¬´ì‹œí•˜ì§€ë§Œ, ë°ì´í„° ì†ì‹¤ ê°€ëŠ¥

### ë°©ë²• 4: BeautifulSoupì— from_encoding ì§€ì •
```python
response = requests.get(url, headers=headers)

# BeautifulSoupì—ê²Œ ì¸ì½”ë”© íŒíŠ¸ ì œê³µ
soup = BeautifulSoup(response.content, 'lxml', from_encoding='utf-8')
```

## ğŸ¯ v4.9.3ì— ì ìš©ëœ í•´ê²°ì±…

### 1. HTTP í—¤ë” ìˆ˜ì •
```python
class NaverPlaceMobileCrawler:
    def __init__(self):
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 14_7_1 like Mac OS X) ...',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Language': 'ko-KR,ko;q=0.9',
            'Accept-Encoding': 'gzip, deflate, br',
            'Accept-Charset': 'utf-8',  # âœ… ì¶”ê°€ë¨
            'Connection': 'keep-alive',
            'Referer': 'https://m.naver.com/'
        }
```

### 2. search_places() ë©”ì„œë“œ ìˆ˜ì •
```python
def search_places(self, keyword, max_results=20):
    url = f"https://m.search.naver.com/search.naver?query={quote(keyword)}"
    
    response = requests.get(url, headers=self.headers, timeout=10)
    response.raise_for_status()
    
    # âœ… í•œê¸€ ê¹¨ì§ ë°©ì§€: ëª…ì‹œì ìœ¼ë¡œ UTF-8 ì¸ì½”ë”© ì„¤ì •
    response.encoding = 'utf-8'
    print("  âœ“ í˜ì´ì§€ ì ‘ê·¼ ì„±ê³µ (ì¸ì½”ë”©: UTF-8)")
    
    soup = BeautifulSoup(response.text, 'lxml')
    # ... ì´í›„ íŒŒì‹± ë¡œì§
```

### 3. _call_naver_local_api() ë©”ì„œë“œ ìˆ˜ì •
```python
def _call_naver_local_api(self, keyword, max_results):
    api_url = f"https://m.map.naver.com/search2/search.naver?query={quote(keyword)}&sm=hty&style=v5"
    response = requests.get(api_url, headers=self.headers, timeout=5)
    
    if response.status_code == 200:
        # âœ… í•œê¸€ ê¹¨ì§ ë°©ì§€
        response.encoding = 'utf-8'
        soup = BeautifulSoup(response.text, 'lxml')
        # ... ì´í›„ íŒŒì‹± ë¡œì§
```

## ğŸ“Š ê²°ê³¼ ë¹„êµ

### âŒ ì´ì „ (í•œê¸€ ê¹¨ì§)
```
ë‹¤ë¶€ë™ì „ê¸°ë°¤ê´€ Â· www.dabu.or.kr â€º include
5â—†ë²¸ì’– â—†ëª„ëº–â—†ë¸³b ~ë²¸ì’–â—†ç“¸ï¿½ â—†ï¿½ëº–>
ì²«íš¨ë± â—†â—† å¨´ê³•â—†â—† æœã‰¿ì¨¬ â—†â—† å±±ê½µ ç¬‘ì‚¦â†’ì²«ï¿½ ë²¸ì’–â—†ç“¸ï¿½(ï¿½ë²ëº¤æª â—†â—†, 963~1021)
```

### âœ… ì´í›„ (ì •ìƒ í•œê¸€)
```
ë‹¤ë¶€ë™ì „ê¸°ë°¤ê´€ Â· www.dabu.or.kr
í¬ì¥ì´ì‚¬ ì „ë¬¸ ì—…ì²´ ì•ˆë‚´
ì„œìš¸ ê°•ë‚¨êµ¬ í¬ì¥ì´ì‚¬ - ë¯¿ì„ ìˆ˜ ìˆëŠ” ì´ì‚¬ ì„œë¹„ìŠ¤
ì „êµ­ ì´ì‚¬ 963-1021, 24ì‹œê°„ ìƒë‹´ ê°€ëŠ¥
```

## ğŸš€ í…ŒìŠ¤íŠ¸ ë°©ë²•

### 1. ì¸ì½”ë”© í™•ì¸
```python
import requests

url = "https://m.search.naver.com/search.naver?query=í¬ì¥ì´ì‚¬"
response = requests.get(url)

print(f"ìë™ ê°ì§€ ì¸ì½”ë”©: {response.encoding}")
# ì¶œë ¥: ISO-8859-1 ë˜ëŠ” None

# ìˆ˜ì • í›„
response.encoding = 'utf-8'
print(f"ì„¤ì •ëœ ì¸ì½”ë”©: {response.encoding}")
# ì¶œë ¥: utf-8
```

### 2. í•œê¸€ í…ìŠ¤íŠ¸ ì¶”ì¶œ í…ŒìŠ¤íŠ¸
```python
from bs4 import BeautifulSoup

# ì˜ëª»ëœ ë°©ë²•
soup1 = BeautifulSoup(response.text, 'lxml')  # response.encoding ì„¤ì • ì „
print(soup1.get_text()[:100])
# ì¶œë ¥: â—†â—† åœ°ì—­â—†â—† æœç´¢â—†... (ê¹¨ì§„ ë¬¸ì)

# ì˜¬ë°”ë¥¸ ë°©ë²•
response.encoding = 'utf-8'
soup2 = BeautifulSoup(response.text, 'lxml')
print(soup2.get_text()[:100])
# ì¶œë ¥: ë„¤ì´ë²„ ê²€ìƒ‰ - í¬ì¥ì´ì‚¬... (ì •ìƒ í•œê¸€)
```

## ğŸ’¡ ì¶”ê°€ íŒ

### 1. ì¸ì½”ë”© ìë™ ê°ì§€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©
```python
import chardet

response = requests.get(url)
detected = chardet.detect(response.content)
print(f"ê°ì§€ëœ ì¸ì½”ë”©: {detected['encoding']}")
# ìë™ìœ¼ë¡œ UTF-8 ê°ì§€

response.encoding = detected['encoding']
```

### 2. ì—¬ëŸ¬ ì¸ì½”ë”© ì‹œë„
```python
encodings = ['utf-8', 'euc-kr', 'cp949']

for enc in encodings:
    try:
        html = response.content.decode(enc)
        soup = BeautifulSoup(html, 'lxml')
        # í•œê¸€ì´ ì •ìƒì ìœ¼ë¡œ íŒŒì‹±ë˜ë©´ ì„±ê³µ
        if 'í•œê¸€' in soup.get_text():
            print(f"ì„±ê³µí•œ ì¸ì½”ë”©: {enc}")
            break
    except:
        continue
```

### 3. BeautifulSoupì˜ UnicodeDammit ì‚¬ìš©
```python
from bs4 import UnicodeDammit

response = requests.get(url)
dammit = UnicodeDammit(response.content)
soup = BeautifulSoup(dammit.unicode_markup, 'lxml')
```

## ğŸ“¦ v4.9.3 ëª¨ë°”ì¼ ë²„ì „ ì‚¬ìš©ë²•

### 1. íŒŒì¼ ë‹¤ìš´ë¡œë“œ
- `ë„¤ì´ë²„_í”Œë ˆì´ìŠ¤_í¬ë¡¤ë§_v4.9.3_ëª¨ë°”ì¼.ipynb` (42KB)

### 2. Google Colab ì—…ë¡œë“œ ë° ì‹¤í–‰
```
ğŸ“± ë„¤ì´ë²„ í”Œë ˆì´ìŠ¤ í¬ë¡¤ë§ v4.9.3 ëª¨ë°”ì¼ ë²„ì „ (í•œê¸€ ê¹¨ì§ í•´ê²°)
   (UTF-8 ì¸ì½”ë”© + ëª¨ë°”ì¼ ê²€ìƒ‰ í”Œë ˆì´ìŠ¤ ì„¹ì…˜ + ERROR 108 ìë™ ë³µêµ¬)
```

### 3. ê²€ìƒ‰ ì‹¤í–‰
- ê²€ìƒ‰ì–´: í¬ì¥ì´ì‚¬, ê°•ë‚¨ì—­ ë§›ì§‘, í™ëŒ€ ì¹´í˜ ë“±
- í•œê¸€ì´ ì •ìƒì ìœ¼ë¡œ í‘œì‹œë¨

## âœ… ì²´í¬ë¦¬ìŠ¤íŠ¸

- [x] `response.encoding = 'utf-8'` ëª…ì‹œì  ì„¤ì •
- [x] `Accept-Charset: utf-8` í—¤ë” ì¶”ê°€
- [x] ëª¨ë“  HTTP ìš”ì²­ì— ì¸ì½”ë”© ì„¤ì • ì ìš©
- [x] í•œê¸€ í…ìŠ¤íŠ¸ ì •ìƒ ì¶œë ¥ í™•ì¸
- [x] ì£¼ì†Œ, ì „í™”ë²ˆí˜¸ ë“± ìƒì„¸ ì •ë³´ ì •ìƒ íŒŒì‹± í™•ì¸
- [x] CSV ë‹¤ìš´ë¡œë“œ ì‹œ í•œê¸€ ì •ìƒ ì €ì¥ í™•ì¸

## ğŸ‰ ê²°ë¡ 

**í•œê¸€ ê¹¨ì§ ë¬¸ì œëŠ” `response.encoding = 'utf-8'` í•œ ì¤„ë¡œ ì™„ì „ í•´ê²°ë©ë‹ˆë‹¤!**

ì´ì œ v4.9.3 ëª¨ë°”ì¼ ë²„ì „ì„ ì‚¬ìš©í•˜ë©´:
- âœ… í•œê¸€ì´ ì •ìƒì ìœ¼ë¡œ í‘œì‹œë¨
- âœ… ë„¤ì´ë²„ ëª¨ë°”ì¼ ê²€ìƒ‰ í”Œë ˆì´ìŠ¤ ì„¹ì…˜ ì •í™• í¬ë¡¤ë§
- âœ… ë¹ ë¥¸ ì†ë„ (5ì´ˆ ì´ë‚´)
- âœ… ERROR 108 ìë™ ë³µêµ¬

---

**ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸**: 2024-12-24  
**ë²„ì „**: v4.9.3 (í•œê¸€ ê¹¨ì§ í•´ê²°)
